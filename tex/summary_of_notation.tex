\section{Summary of Notation}
% We adopt a similar notation to \citeauthor{ReinforcementLearningIntroduction_Sutton.Barto_2018} \cite{ReinforcementLearningIntroduction_Sutton.Barto_2018}.
% Capital letters are used for random variables, whereas lower case letters are used for the values of
% random variables and for scalar functions.
% Quantities that are required to be real-valued vectors are written in bold and in lower case (even if random variables).
% Matrices are bold capitals.

\begin{tabular}{| r  l  r |}
    \hline
    \textbf{Symbol} & \textbf{Description}                   & \textbf{Reference}                       \\
    \hline
    $s$             & state                                  & \ref{sec:markov}                         \\
    $a$             & action                                 & \ref{sec:markov}                         \\
    $r$             & reward                                 & \ref{sec:markov}                         \\
    $t$             & timestep                               & \ref{sec:markov}                         \\
    $T$             & terminal timestep                      & \ref{sec:markov}                         \\
    $\gamma$        & discount                               & \ref{sec:markov}                         \\
    $o$             & partially observable environment frame                                            \\
    $G$             & N-step return                          & \ref{sec:policies_and_functions}         \\
    $G^N$           & N-step return                          & \ref{sec:policies_and_functions}         \\
    $V$             & value function                         & \ref{sec:policies_and_functions}         \\
    $Q$             & state-action value function            & \ref{sec:policies_and_functions}         \\
    $\delta$        & TD-error or value diff                 & \ref{sec:replay}                         \\
    $\mathcal{A}^e$ & environment action space               & \ref{sec:a_aug}                          \\
    $\mathcal{A}^a$ & agent action space                     & \ref{sec:a_aug}                          \\
    $\mathcal{S}$   & state space                                                                       \\
    $\mathcal{O}$   & observation space                                                                 \\
    $\mathcal{T}_t$ & step sample                            & \ref{sec:targets}                        \\
    $\mathcal{T}$   & trajectory sample                                                                 \\
    $\mathcal{L}$   & loss function                                                                     \\

    \hline
    $\mathbf{x}$    & hidden state                                                                      \\
    $h$             & representation function                                                           \\
    $g$             & dynamics function                                                                 \\
    $f$             & prediction function                                                               \\
    $\varrho$       & projection function                                                               \\
    $v^i$           & value prediction                                                                  \\

    \hline
    $B$             & batch size                                                                        \\
    $H$             & height                                 & \ref{sec:env_bridge}                     \\
    $W$             & width                                  & \ref{sec:env_bridge}                     \\
    $C_e$           & environment channels                   & \ref{sec:env_bridge}                     \\
    $C_h$           & history channels                       & \ref{sec:history_stacking}               \\
    $C_x$           & hidden space channels                  &                                          \\
    $K$             & number of unrolled steps               & \ref{sec:targets}                        \\
    $L$             & history length                         & \ref{sec:targets}                        \\
    $N$             & bootstrap length for N-step return     & \ref{sec:targets}                        \\
    $A$             & dimension of action                                                               \\
    \hline
    $Z$             & support of the scalar transformation   & \ref{sec:scalar_transform}, \ref{sec:nn} \\
\end{tabular}
